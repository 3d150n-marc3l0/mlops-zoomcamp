{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c51efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4acf73a0-51b5-4663-9bb8-8eb947863e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17206f57-e788-4523-b338-7021e545368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/codespace/.local/lib/python3.10/site-packages (from pyarrow) (1.26.4)\n",
      "Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-16.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef880a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7836ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c08294",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d40026-ae80-4343-be95-afc3c7cf1163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = \"Data\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "DATA_URL = \"https://d37ci6vzurychx.cloudfront.net\"\n",
    "taxi_type = \"yellow\"\n",
    "year = 2023\n",
    "month = 3\n",
    "input_file = f'{DATA_URL}/trip-data/{taxi_type}_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "print(f\"input_file: {input_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc734b35-e407-47a7-9411-42084ee8412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Data directory exists\n",
      "The output directory exists\n"
     ]
    }
   ],
   "source": [
    "for dir in [DATASET_DIR, OUTPUT_DIR]:\n",
    "    if os.path.isdir(dir): \n",
    "        print(f\"The {dir} directory exists\")\n",
    "        continue\n",
    "    # if the directory is  \n",
    "    # not present then create it. \n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    print(f\"The {dir} directory is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4854399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "669fda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8692b7c2-3a54-4c86-8372-3b253e37a68a",
   "metadata": {},
   "source": [
    "## Q1. Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a55366-51b3-430b-9b37-c4eb479d688e",
   "metadata": {},
   "source": [
    "\n",
    "We'll start with the same notebook we ended up with in homework 1.\n",
    "We cleaned it a little bit and kept only the scoring part. You can find the initial notebook [here](homework/starter.ipynb).\n",
    "\n",
    "Run this notebook for the March 2023 data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f276aeba-2cdf-4b88-898f-4edf1bf8a062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.247488852238703"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Std.\n",
    "y_pred.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29840f27-81e6-4e0c-9fb3-98d08df9c4ba",
   "metadata": {},
   "source": [
    "What's the standard deviation of the predicted duration for this dataset?\n",
    "\n",
    "* 1.24\n",
    "* **6.24**\n",
    "* 12.28\n",
    "* 18.28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41723ef-0198-4c7a-be28-46d174939fc2",
   "metadata": {},
   "source": [
    "## Q2. Preparing the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8ccb0-7b9b-4e8d-a99b-4f5d508fc6db",
   "metadata": {},
   "source": [
    "Like in the course videos, we want to prepare the dataframe with the output. \n",
    "\n",
    "First, let's create an artificial `ride_id` column:\n",
    "\n",
    "```python\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "```\n",
    "\n",
    "Next, write the ride id and the predictions to a dataframe with results. \n",
    "\n",
    "Save it as parquet:\n",
    "\n",
    "```python\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c445ff9-12d6-487a-aba1-1f4c61cb2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acc86607-ea62-43e6-a6b9-e419ca8bd3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[['ride_id']].copy()\n",
    "df_result['prediction'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5901f6ae-5547-4493-9b4e-655350d47373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_file output/pred_yellow_tripdata_2023-03.parquet...\n"
     ]
    }
   ],
   "source": [
    "output_file = f'{OUTPUT_DIR}/pred_yellow_tripdata_{year:04}-{month:02}.parquet'\n",
    "print(f'output_file {output_file}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ea60f1e-5c2c-4e3f-bda6-4493c1fbbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c3396d0-0cfd-402e-bac0-603d86f33de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 199M\n",
      "-rw-rw-rw- 1 codespace codespace 66M Jun 17 11:31 pred_yellow_tripdata_2023-03.parquet\n",
      "-rw-rw-rw- 1 codespace codespace 66M Jun 17 11:30 pred_yellow_tripdata_2023-04.parquet\n",
      "-rw-rw-rw- 1 codespace codespace 68M Jun 17 10:59 pred_yellow_tripdata_2023-05.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e07edd7-5e1b-405f-a723-3e9c0dc6b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size in Bytes is 65.46 MB\n"
     ]
    }
   ],
   "source": [
    "# Get size of file in bytes\n",
    "file_stats = os.stat(output_file)\n",
    "file_size = file_stats.st_size  / (1024 * 1024)\n",
    "# Imprimir size in MB\n",
    "print(f\"File Size in Bytes is {file_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a892ee-4fdc-4bc8-a50c-75e3c6330c80",
   "metadata": {},
   "source": [
    "What's the size of the output file?\n",
    "\n",
    "* 36M\n",
    "* 46M\n",
    "* 56M\n",
    "* **66M**\n",
    "\n",
    "__Note:__ Make sure you use the snippet above for saving the file. It should contain only these two columns. For this question, don't change the\n",
    "dtypes of the columns and use `pyarrow`, not `fastparquet`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78289933-bb96-4ed2-b7a3-ccd648863a32",
   "metadata": {},
   "source": [
    "## Q3. Creating the scoring script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82277a1e-d32c-4853-88d2-7382f183585e",
   "metadata": {},
   "source": [
    "Now let's turn the notebook into a script. \n",
    "\n",
    "Which command you need to execute for that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6151b7-f553-46c5-a7de-44c46db2f651",
   "metadata": {},
   "source": [
    "**nbconvert**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ce826-8d0d-498b-8db5-01cac5fa5cd0",
   "metadata": {},
   "source": [
    "## Q4. Virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d62e5b-b414-4bcf-b0ef-31b531f87b5a",
   "metadata": {},
   "source": [
    "Now let's put everything into a virtual environment. We'll use pipenv for that.\n",
    "\n",
    "Install all the required libraries. Pay attention to the Scikit-Learn version: it should be the same as in the starter\n",
    "notebook.\n",
    "\n",
    "After installing the libraries, pipenv creates two files: `Pipfile`\n",
    "and `Pipfile.lock`. The `Pipfile.lock` file keeps the hashes of the\n",
    "dependencies we use for the virtual env.\n",
    "\n",
    "What's the first hash for the Scikit-Learn dependency?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d8053-47aa-4360-8b87-cbd4af0970a5",
   "metadata": {},
   "source": [
    "057b991ac64b3e75c9c04b5f9395eaf19a6179244c089afdebaad98264bff37c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c770de-c51d-462e-a9b8-7182832d2f68",
   "metadata": {},
   "source": [
    "## Q5. Parametrize the script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6738ac29-4169-4715-ab7e-adae21af8307",
   "metadata": {},
   "source": [
    "Let's now make the script configurable via CLI. We'll create two \n",
    "parameters: year and month.\n",
    "\n",
    "Run the script for April 2023. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb70b6df-3851-4a85-83ca-644d918752a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_type = 'yellow'\n",
    "year = 2023\n",
    "month = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1310d476-420a-4bec-9e61-f2b816b20c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Data directory exists\n",
      "The output directory exists\n",
      "starter.py\n",
      "Dockerfile\n",
      "Data\n",
      "output\n",
      "Pipfile\n",
      "model.bin\n",
      "Pipfile.lock\n",
      ".ipynb_checkpoints\n",
      "starter.ipynb\n",
      "reading data https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet...\n",
      "predicting...\n",
      "Loading model model.bin...\n",
      "the mean of prediction is 14.292282936862449\n",
      "save results output/pred_yellow_tripdata_2023-04.parquet...\n"
     ]
    }
   ],
   "source": [
    "!python starter.py {taxi_type} {year} {month}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272c707e-5c05-48a1-ae2c-49bb8ec5dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 196M\n",
      "-rw-rw-rw- 1 codespace codespace 66M Jun 17 11:31 pred_yellow_tripdata_2023-03.parquet\n",
      "-rw-rw-rw- 1 codespace codespace 64M Jun 17 11:32 pred_yellow_tripdata_2023-04.parquet\n",
      "-rw-rw-rw- 1 codespace codespace 68M Jun 17 10:59 pred_yellow_tripdata_2023-05.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624302b-8944-49b9-9166-e6610c79e8f4",
   "metadata": {},
   "source": [
    "What's the mean predicted duration? \n",
    "\n",
    "* 7.29\n",
    "* **14.29**\n",
    "* 21.29\n",
    "* 28.29\n",
    "\n",
    "Hint: just add a print statement to your script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413ca64-df3e-4998-985d-338e3a43c815",
   "metadata": {},
   "source": [
    "## Q6. Docker container "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5658e7-b608-4656-a831-ac6486eb3a7a",
   "metadata": {},
   "source": [
    "Finally, we'll package the script in the docker container. \n",
    "For that, you'll need to use a base image that we prepared. \n",
    "\n",
    "This is what the content of this image is:\n",
    "```\n",
    "FROM python:3.10.13-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY [ \"model2.bin\", \"model.bin\" ]\n",
    "```\n",
    "\n",
    "Note: you don't need to run it. We have already done it.\n",
    "\n",
    "It is pushed it to [`agrigorev/zoomcamp-model:mlops-2024-3.10.13-slim`](https://hub.docker.com/layers/agrigorev/zoomcamp-model/mlops-2024-3.10.13-slim/images/sha256-f54535b73a8c3ef91967d5588de57d4e251b22addcbbfb6e71304a91c1c7027f?context=repo),\n",
    "which you need to use as your base image.\n",
    "\n",
    "That is, your Dockerfile should start with:\n",
    "\n",
    "```docker\n",
    "FROM agrigorev/zoomcamp-model:mlops-2024-3.10.13-slim\n",
    "\n",
    "# do stuff here\n",
    "```\n",
    "\n",
    "This image already has a pickle file with a dictionary vectorizer\n",
    "and a model. You will need to use them.\n",
    "\n",
    "Important: don't copy the model to the docker image. You will need\n",
    "to use the pickle file already in the image. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb654e-93b9-4776-8c87-94d3c0ad8fa2",
   "metadata": {},
   "source": [
    "Now run the script with docker. What's the mean predicted duration\n",
    "for **May 2023**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58041a1c-c918-46f8-b018-639dd9d8a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_type = 'yellow'\n",
    "year = 2023\n",
    "month = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c9dd696-cae8-412e-abaf-cf23b9745ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Data directory exists\n",
      "The output directory exists\n",
      "starter.py\n",
      "Dockerfile\n",
      "Data\n",
      "output\n",
      "Pipfile\n",
      "model.bin\n",
      "Pipfile.lock\n",
      ".ipynb_checkpoints\n",
      "starter.ipynb\n",
      "reading data https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet...\n",
      "predicting...\n",
      "Loading model model.bin...\n",
      "the mean of prediction is 14.242595513316317\n",
      "save results output/pred_yellow_tripdata_2023-05.parquet...\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "!python starter.py {taxi_type} {year} {month}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b289e0-79e1-4465-beda-c12e9e5d2814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build image\n",
    "!docker build -t mlops-zoomcamp-model:2024-3.10.13-slim ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "782bfc8d-b892-4642-923c-44f7433c7234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Data directory is created\n",
      "The output directory is created\n",
      "Data\n",
      "output\n",
      "starter.py\n",
      "Pipfile\n",
      "Pipfile.lock\n",
      "model.bin\n",
      "reading data https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet...\n",
      "predicting...\n",
      "Loading model model.bin...\n",
      "the mean of prediction is 0.19174419265916945\n",
      "save results output/pred_yellow_tripdata_2023-05.parquet...\n"
     ]
    }
   ],
   "source": [
    "# Image model\n",
    "!docker run -i -t mlops-zoomcamp-model:2024-3.10.13-slim {taxi_type} {year} {month}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e310fe2-d0c7-43a1-b5db-bb9ff9e64340",
   "metadata": {},
   "source": [
    "\n",
    "* **0.19**\n",
    "* 7.24\n",
    "* 14.24\n",
    "* 21.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24c7c5-7c8b-4383-b837-0b7f70bdf97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
